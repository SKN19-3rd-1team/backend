"""
ReAct ìŠ¤íƒ€ì¼ ì—ì´ì „íŠ¸ë¥¼ ìœ„í•œ LangChain Tools ì •ì˜

ì´ íŒŒì¼ì˜ í•¨ìˆ˜ë“¤ì€ @tool ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ LLMì´ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” íˆ´ë¡œ ë“±ë¡ë©ë‹ˆë‹¤.

** ReAct íŒ¨í„´ì—ì„œì˜ íˆ´ ì—­í•  **
LLMì´ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³ , í•„ìš”ì‹œ ììœ¨ì ìœ¼ë¡œ ì´ íˆ´ë“¤ì„ í˜¸ì¶œí•˜ì—¬ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

** ì œê³µë˜ëŠ” íˆ´ë“¤ **
1. list_departments: í•™ê³¼ ëª©ë¡ ì¡°íšŒ
2. get_universities_by_department: íŠ¹ì • í•™ê³¼ê°€ ìˆëŠ” ëŒ€í•™ ì¡°íšŒ
3. get_major_career_info: ì „ê³µë³„ ì§„ì¶œ ì§ì—…/ë¶„ì•¼ ì¡°íšŒ
4. get_search_help: ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì‚¬ìš© ê°€ì´ë“œ ì œê³µ

** ì‘ë™ ë°©ì‹ **
1. LLMì´ ì‚¬ìš©ì ì§ˆë¬¸ ë¶„ì„
2. LLMì´ í•„ìš”í•œ íˆ´ ì„ íƒ ë° íŒŒë¼ë¯¸í„° ê²°ì •
3. íˆ´ ì‹¤í–‰ (ì´ íŒŒì¼ì˜ í•¨ìˆ˜ í˜¸ì¶œ)
4. íˆ´ ê²°ê³¼ë¥¼ LLMì—ê²Œ ì „ë‹¬
5. LLMì´ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±
"""

from typing import List, Dict, Any, Optional
from langchain_core.tools import tool
import re
import json
from pathlib import Path
from backend.config import get_settings

from .vectorstore import get_major_vectorstore
from .loader import load_major_detail


def _log_tool_start(tool_name: str, description: str) -> None:
    # ê° LangChain Toolì´ ì–´ë–¤ ëª©ì ì„ ê°€ì§€ëŠ”ì§€ ì½˜ì†”ì— ëª…í™•íˆ ë‚¨ê¸´ë‹¤
    print(f"[Tool:{tool_name}] ì‹œì‘ - {description}")


def _log_tool_result(tool_name: str, outcome: str) -> None:
    # íˆ´ ì‹¤í–‰ ê²°ê³¼(ë°˜í™˜ ê±´ìˆ˜, ìƒíƒœ ë©”ì‹œì§€ ë“±)ë¥¼ ìš”ì•½ ì¶œë ¥
    print(f"[Tool:{tool_name}] ê²°ê³¼ - {outcome}")


def _get_tool_usage_guide() -> str:
    """
    ì‚¬ìš©ìì—ê²Œ ì œê³µí•  íˆ´ ì‚¬ìš© ê°€ì´ë“œ ë©”ì‹œì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    return """
ê²€ìƒ‰ ê°€ëŠ¥í•œ ë°©ë²•ë“¤:

1. **í•™ê³¼ ëª©ë¡ ì¡°íšŒ**
   - ì˜ˆì‹œ: "ì–´ë–¤ í•™ê³¼ë“¤ì´ ìˆì–´?", "ì»´í“¨í„° ê´€ë ¨ í•™ê³¼ ì•Œë ¤ì¤˜", "ê³µëŒ€ì—ëŠ” ì–´ë–¤ í•™ê³¼ê°€ ìˆì–´?"
   - ì „ì²´ í•™ê³¼ ëª©ë¡ ë˜ëŠ” í‚¤ì›Œë“œë¡œ í•„í„°ë§ëœ í•™ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

2. **íŠ¹ì • í•™ê³¼ê°€ ìˆëŠ” ëŒ€í•™ ì¡°íšŒ**
   - ì˜ˆì‹œ: "ì»´í“¨í„°ê³µí•™ê³¼ê°€ ìˆëŠ” ëŒ€í•™ ì•Œë ¤ì¤˜", "ì†Œí”„íŠ¸ì›¨ì–´í•™ë¶€ ê°œì„¤ ëŒ€í•™"
   - íŠ¹ì • í•™ê³¼ë¥¼ ê°œì„¤í•œ ëŒ€í•™ ëª©ë¡ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

3. **ì „ê³µë³„ ì§„ì¶œ ì§ì—…/ë¶„ì•¼ ì¡°íšŒ**
   - ì˜ˆì‹œ: "ì»´ê³µ ì¡¸ì—…í•˜ë©´ ì–´ë–¤ ì§ì—…?", "OOí•™ê³¼ ì§„ë¡œ ì•Œë ¤ì¤˜"
   - get_major_career_info íˆ´ì„ í˜¸ì¶œí•˜ì—¬ major_detail.jsonì˜ `job`/`enter_field` ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ë” ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤!
"""


def _strip_html(value: str) -> str:
    return re.sub(r"<[^>]+>", " ", value or "")

# ===== ì „ê³µ ëŒ€ë¶„ë¥˜/ì„¸ë¶€ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬ =====
# ===== ì „ê³µ ëŒ€ë¶„ë¥˜/ì„¸ë¶€ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬ =====
def _load_major_categories() -> dict[str, list[str]]:
    """
    backend/data/major_categories.json íŒŒì¼ì—ì„œ ì „ê³µ ë¶„ë¥˜ ì •ë³´ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    """
    try:
        settings = get_settings()
        # Assuming major_categories.json is in the same directory as major_detail.json
        # or we can construct the path relative to this file or project root.
        # Let's try to use a fixed path or derive it.
        # Since we just created it in backend/data/major_categories.json:
        json_path = Path("/home/maroco/major_mentor/backend/data/major_categories.json")
        if not json_path.exists():
             # Fallback or try relative path if absolute fails in different envs (though we are in a specific env)
             base_dir = Path(__file__).parent.parent / "data"
             json_path = base_dir / "major_categories.json"
        
        if json_path.exists():
            return json.loads(json_path.read_text(encoding="utf-8"))
        return {}
    except Exception as e:
        # íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥ ë° ë¹ˆ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜
        print(f"âš ï¸ Failed to load major categories: {e}")
        return {}

MAIN_CATEGORIES = _load_major_categories()

# list_departments ì¿¼ë¦¬ í™•ì¥ í•¨ìˆ˜
def _expand_category_query(query: str) -> tuple[list[str], str]:
    """
    list_departmentsìš© ì¿¼ë¦¬ í™•ì¥:
    - ëŒ€ë¶„ë¥˜(key)ë¥¼ ë„£ìœ¼ë©´: í•´ë‹¹ keyì— ì†í•œ ëª¨ë“  ì„¸ë¶€ valueë“¤ì„ í’€ì–´ì„œ í‚¤ì›Œë“œë¡œ ì‚¬ìš©
    - ì„¸ë¶€ ë¶„ë¥˜(value)ë¥¼ ë„£ìœ¼ë©´: "ì»´í“¨í„° / ì†Œí”„íŠ¸ì›¨ì–´ / ì¸ê³µì§€ëŠ¥" â†’ ["ì»´í“¨í„°","ì†Œí”„íŠ¸ì›¨ì–´","ì¸ê³µì§€ëŠ¥"]
    - ê·¸ ì™¸ ì¼ë°˜ í…ìŠ¤íŠ¸: "/", "," ê¸°ì¤€ìœ¼ë¡œ í† í° ë‚˜ëˆˆ ë’¤ ì‚¬ìš©

    Returns:
        tokens: ["ì»´í“¨í„°", "ì†Œí”„íŠ¸ì›¨ì–´", "ì¸ê³µì§€ëŠ¥", ...]
        embed_text: "ì»´í“¨í„° ì†Œí”„íŠ¸ì›¨ì–´ ì¸ê³µì§€ëŠ¥ ..." (ì„ë² ë”©ì— ë„£ì„ ë¬¸ìì—´)
    """
    raw = query.strip()
    if not raw:
        return [], ""

    tokens: list[str] = []

    # 1) ëŒ€ë¶„ë¥˜(key) ì…ë ¥ì¸ ê²½ìš° â†’ í•´ë‹¹ keyì˜ ëª¨ë“  ì„¸ë¶€ valueë¥¼ í•œêº¼ë²ˆì— í’€ì–´ì„œ ì‚¬ìš©
    if raw in MAIN_CATEGORIES:
        details = MAIN_CATEGORIES[raw]
        for item in details:
            parts = [p.strip() for p in re.split(r"[\/,()]", item) if p.strip()]
            tokens.extend(parts)

    # 2) ì„¸ë¶€ ë¶„ë¥˜(value) ê·¸ëŒ€ë¡œ ë“¤ì–´ì˜¨ ê²½ìš°
    elif any(raw in v for values in MAIN_CATEGORIES.values() for v in values):
        parts = [p.strip() for p in re.split(r"[\/,()]", raw) if p.strip()]
        tokens.extend(parts)

    # 3) ì¼ë°˜ í…ìŠ¤íŠ¸ ì¿¼ë¦¬ (ì˜ˆ: "ì»´í“¨í„° / ì†Œí”„íŠ¸ì›¨ì–´ / ì¸ê³µì§€ëŠ¥", "AI, ë°ì´í„°")
    else:
        parts = [p.strip() for p in re.split(r"[\/,]", raw) if p.strip()]
        if parts:
            tokens.extend(parts)
        else:
            tokens.append(raw)

    # ì¤‘ë³µ ì œê±°(ìˆœì„œ ìœ ì§€)
    seen = set()
    dedup_tokens = []
    for t in tokens:
        if t not in seen:
            seen.add(t)
            dedup_tokens.append(t)

    embed_text = " ".join(dedup_tokens) if dedup_tokens else raw
    return dedup_tokens, embed_text


# ==================== Major detail helpers ====================
_MAJOR_RECORDS_CACHE = None
_MAJOR_ID_MAP: dict[str, Any] = {}
_MAJOR_NAME_MAP: dict[str, Any] = {}
_MAJOR_ALIAS_MAP: dict[str, Any] = {}


def _normalize_major_key(value: str) -> str:
    return re.sub(r"\s+", "", (value or "").lower())


def _ensure_major_records():
    global _MAJOR_RECORDS_CACHE, _MAJOR_ID_MAP, _MAJOR_NAME_MAP, _MAJOR_ALIAS_MAP
    if _MAJOR_RECORDS_CACHE is not None:
        return

    records = load_major_detail()
    _MAJOR_RECORDS_CACHE = records
    id_map: dict[str, Any] = {}
    name_map: dict[str, Any] = {}
    alias_map: dict[str, Any] = {}

    for record in records:
        if record.major_id:
            id_map[record.major_id] = record

        if record.major_name:
            norm_name = _normalize_major_key(record.major_name)
            if norm_name:
                name_map[norm_name] = record
                alias_map.setdefault(norm_name, record)

        for alias in getattr(record, "department_aliases", []) or []:
            norm_alias = _normalize_major_key(alias)
            if norm_alias and norm_alias not in alias_map:
                alias_map[norm_alias] = record

    _MAJOR_ID_MAP = id_map
    _MAJOR_NAME_MAP = name_map
    _MAJOR_ALIAS_MAP = alias_map


def _get_major_records() -> list[Any]:
    _ensure_major_records()
    return _MAJOR_RECORDS_CACHE or []


def _lookup_major_by_name(name: str) -> Any | None:
    if not name:
        return None
    _ensure_major_records()
    key = _normalize_major_key(name)
    return _MAJOR_NAME_MAP.get(key) or _MAJOR_ALIAS_MAP.get(key)


def _search_major_records_by_vector(query_text: str, limit: int) -> list[Any]:
    if not query_text.strip():
        return []

    _ensure_major_records()
    try:
        vectorstore = get_major_vectorstore()
    except Exception as exc:
        print(f"âš ï¸  Unable to load major vectorstore for query '{query_text}': {exc}")
        return []

    try:
        docs = vectorstore.similarity_search(query_text, k=max(limit, 5))
    except Exception as exc:
        print(f"âš ï¸  Vector search failed for majors query '{query_text}': {exc}")
        return []

    matches: list[Any] = []
    seen_ids: set[str] = set()
    for doc in docs:
        meta = doc.metadata or {}
        major_id = meta.get("major_id")
        if not major_id or major_id in seen_ids:
            continue
        record = _MAJOR_ID_MAP.get(major_id)
        if record is None:
            continue
        seen_ids.add(major_id)
        matches.append(record)
        if len(matches) >= limit:
            break
    return matches


def _filter_records_by_tokens(tokens: list[str], limit: int) -> list[Any]:
    if not tokens:
        return []
    normalized = [t.lower() for t in tokens if t]
    if not normalized:
        return []

    results: list[Any] = []
    seen_ids: set[str] = set()
    for record in _get_major_records():
        target = _normalize_major_key(record.major_name)
        if all(tok in target for tok in normalized):
            if record.major_id and record.major_id in seen_ids:
                continue
            if record.major_id:
                seen_ids.add(record.major_id)
            results.append(record)
            if len(results) >= limit:
                break
    return results


def _find_majors(query: str, limit: int = 10) -> list[Any]:
    """
    í†µí•© ì „ê³µ ê²€ìƒ‰ í•¨ìˆ˜:
    1. ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ì „ê³µëª… í™•ì¸
    2. (ì •í™• ì¼ì¹˜ ì—†ì„ ì‹œ) í† í° ë³„ì¹­ í™•ì¸
    3. ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ (í•­ìƒ ìˆ˜í–‰í•˜ì—¬ ì—°ê´€ ì „ê³µ í¬í•¨)
    4. (ê²°ê³¼ ì—†ì„ ì‹œ) í† í° í¬í•¨ ì—¬ë¶€ í•„í„°ë§
    """
    _ensure_major_records()
    matches: list[Any] = []
    seen_ids: set[str] = set()

    # 1. Direct Match (ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ì „ê³µëª… ê²€ìƒ‰)
    direct = _lookup_major_by_name(query)
    if direct:
        matches.append(direct)
        if direct.major_id:
            seen_ids.add(direct.major_id)

    tokens, embed_text = _expand_category_query(query)

    # 2. Alias Match (only if no direct match)
    # 2. ë³„ì¹­ ê²€ìƒ‰ (ì •í™•í•œ ë§¤ì¹­ì´ ì—†ì„ ê²½ìš°, í† í°ë³„ë¡œ ë³„ì¹­ í™•ì¸)
    if not matches and tokens:
        for token in tokens:
            alias_match = _lookup_major_by_name(token)
            if alias_match and alias_match not in matches:
                matches.append(alias_match)
                if alias_match.major_id:
                    seen_ids.add(alias_match.major_id)

    # 3. Vector Search (ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ - í•­ìƒ ìˆ˜í–‰í•˜ì—¬ ì—°ê´€ ì „ê³µ í¬í•¨)
    search_text = embed_text or query
    vector_matches = _search_major_records_by_vector(search_text, limit=max(limit * 3, 10))
    for record in vector_matches:
        if record.major_id and record.major_id in seen_ids:
            continue
        matches.append(record)
        if record.major_id:
            seen_ids.add(record.major_id)
        if len(matches) >= max(limit, 10):
            break

    # 4. Fallback Token Filter (if no matches yet)
    # 4. í† í° í•„í„°ë§ (ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ê²½ìš° ìµœí›„ì˜ ìˆ˜ë‹¨)
    if not matches and tokens:
        token_matches = _filter_records_by_tokens(tokens, limit=max(limit, 10))
        for record in token_matches:
            if record.major_id and record.major_id in seen_ids:
                continue
            matches.append(record)
            if record.major_id:
                seen_ids.add(record.major_id)
            if len(matches) >= limit:
                break

    return matches[:limit]


def _format_department_output(
    query: str,
    departments: list[str],
    total_available: int | None = None,
    dept_univ_map: Optional[dict[str, list[str]]] = None,
) -> str:
    formatted_output = "=" * 80 + "\n"
    formatted_output += f"ğŸ¯ ê²€ìƒ‰ ê²°ê³¼: '{query}'ì— ëŒ€í•œ í•™ê³¼ {len(departments)}ê°œ\n"
    if total_available is not None:
        formatted_output += f"(ì´ {total_available}ê°œ ì¤‘ ìƒìœ„ {len(departments)}ê°œ í‘œì‹œ)\n"
    formatted_output += "=" * 80 + "\n\n"
    formatted_output += "ğŸ“‹ **ì •í™•í•œ í•™ê³¼ëª… ëª©ë¡** (ì•„ë˜ ë°±í‹± ì•ˆì˜ ì´ë¦„ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬í•˜ì„¸ìš”):\n\n"

    for i, dept in enumerate(departments, 1):
        formatted_output += f"{i}. `{dept}`\n"
        if dept_univ_map:
            universities = dept_univ_map.get(dept)
            if universities:
                formatted_output += f"   - ê°œì„¤ ëŒ€í•™ ì˜ˆì‹œ: {', '.join(universities)}\n"

    formatted_output += "\n" + "=" * 80 + "\n"
    formatted_output += "ğŸš¨ **ì¤‘ìš” - ë‹µë³€ ì‘ì„± ê·œì¹™**:\n"
    formatted_output += "   1. ë°±í‹±(`) ì•ˆì˜ í•™ê³¼ëª…ì„ **í•œ ê¸€ìë„ ë°”ê¾¸ì§€ ë§ê³ ** ë³µì‚¬í•˜ì„¸ìš”\n"
    formatted_output += "   2. ìœ„ ëª©ë¡ì— ì—†ëŠ” í•™ê³¼ëª…ì„ ì ˆëŒ€ ë§Œë“¤ì§€ ë§ˆì„¸ìš”\n"
    formatted_output += "   3. 'ê³¼', 'ë¶€', 'ì „ê³µ' ë“±ì„ ì¶”ê°€/ì œê±°í•˜ì§€ ë§ˆì„¸ìš”\n\n"
    formatted_output += "   ì˜¬ë°”ë¥¸ ì˜ˆì‹œ:\n"
    formatted_output += "   - ëª©ë¡ì— `ì§€ëŠ¥ë¡œë´‡`ì´ ìˆìœ¼ë©´ â†’ ë‹µë³€: **ì§€ëŠ¥ë¡œë´‡** âœ…\n"
    formatted_output += "   - ëª©ë¡ì— `í™”ê³µí•™ë¶€`ê°€ ìˆìœ¼ë©´ â†’ ë‹µë³€: **í™”ê³µí•™ë¶€** âœ…\n\n"
    formatted_output += "   ì˜ëª»ëœ ì˜ˆì‹œ:\n"
    formatted_output += "   - ëª©ë¡ì— `ì§€ëŠ¥ë¡œë´‡`ì¸ë° â†’ ë‹µë³€: **ì§€ëŠ¥ë¡œë´‡ê³µí•™ê³¼** âŒ (ë‹¨ì–´ ì¶”ê°€)\n"
    formatted_output += "   - ëª©ë¡ì— `í™”ê³µí•™ë¶€`ì¸ë° â†’ ë‹µë³€: **í™”ê³µí•™ê³¼** âŒ (í•™ë¶€â†’í•™ê³¼ ë³€ê²½)\n"
    formatted_output += "=" * 80
    return formatted_output


def _extract_university_entries(record: Any) -> list[Dict[str, str]]:
    entries: list[Dict[str, str]] = []
    raw_list = getattr(record, "university", None)
    if not isinstance(raw_list, list):
        return entries

    seen: set[tuple[str, str, str]] = set()
    for item in raw_list:
        school = (item.get("schoolName") or "").strip()
        campus = (item.get("campus_nm") or item.get("campusNm") or "").strip()
        major_name = (item.get("majorName") or "").strip()
        area = (item.get("area") or "").strip()
        url = (item.get("schoolURL") or "").strip()

        dept_label = major_name or record.major_name
        if not school:
            continue

        dedup_key = (school, dept_label, campus)
        if dedup_key in seen:
            continue
        seen.add(dedup_key)

        entry: Dict[str, str] = {
            "university": school,
            "college": campus or area or "",
            "department": dept_label,
        }
        if area:
            entry["area"] = area
        if campus:
            entry["campus"] = campus
        if url:
            entry["url"] = url
        if record.major_name and record.major_name != dept_label:
            entry["standard_major_name"] = record.major_name

        entries.append(entry)

    return entries


def _collect_university_pairs(record: Any, limit: int = 3) -> list[str]:
    entries = _extract_university_entries(record)
    pairs: list[str] = []
    for entry in entries[:limit]:
        university = entry.get("university", "").strip()
        department = entry.get("department", "").strip()
        label = " ".join(token for token in [university, department] if token)
        if label and label not in pairs:
            pairs.append(label)
    return pairs


def _dedup_preserve_order(items: list[str]) -> list[str]:
    seen: set[str] = set()
    ordered: list[str] = []
    for item in items:
        if item and item not in seen:
            seen.add(item)
            ordered.append(item)
    return ordered


def _extract_job_list(job_text: str) -> list[str]:
    if not job_text:
        return []
    parts = re.split(r"[,/\n]", job_text)
    cleaned = [part.strip() for part in parts if len(part.strip()) > 1]
    return _dedup_preserve_order(cleaned)


def _format_enter_field(record: Any) -> list[Dict[str, str]]:
    """
    major_detail.jsonì˜ enter_field êµ¬ì¡°ë¥¼ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì£¼ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ì •ë¦¬í•œë‹¤.
    """
    formatted: list[Dict[str, str]] = []
    raw_list = getattr(record, "enter_field", None)
    if not isinstance(raw_list, list):
        return formatted

    for item in raw_list:
        if not isinstance(item, dict):
            continue
        category = (item.get("gradeuate") or item.get("graduate") or "").strip()
        description = _strip_html(item.get("description") or "").strip()
        if not category and not description:
            continue
        entry: Dict[str, str] = {}
        if category:
            entry["category"] = category
        if description:
            entry["description"] = description
        formatted.append(entry)

    return formatted


def _format_career_activities(record: Any) -> list[Dict[str, str]]:
    """
    í•™ê³¼ ì¤€ë¹„ í™œë™(career_act)ì„ act_name/description ì§ìœ¼ë¡œ ì •ë¦¬í•´ LLMì´ ë°”ë¡œ ì½ë„ë¡ ë°˜í™˜í•œë‹¤.
    """
    activities: list[Dict[str, str]] = []
    raw_list = getattr(record, "career_act", None)
    if not isinstance(raw_list, list):
        return activities

    for item in raw_list:
        if not isinstance(item, dict):
            continue
        name = (item.get("act_name") or "").strip()
        description = _strip_html(item.get("act_description") or "").strip()
        if not name and not description:
            continue
        entry: Dict[str, str] = {}
        if name:
            entry["act_name"] = name
        if description:
            entry["act_description"] = description
        activities.append(entry)

    return activities


def _parse_qualifications(record: Any) -> tuple[str, list[str]]:
    """
    qualifications í•„ë“œë¥¼ ë¬¸ìì—´/ë¦¬ìŠ¤íŠ¸ ì—¬ë¶€ì— ê´€ê³„ì—†ì´ ì¼ê´€ëœ ë¦¬ìŠ¤íŠ¸ì™€ ë¬¸ìì—´ë¡œ ë³€í™˜í•œë‹¤.
    """
    raw_value = getattr(record, "qualifications", None)
    if raw_value is None:
        return "", []

    tokens: list[str] = []
    if isinstance(raw_value, list):
        tokens = [str(item).strip() for item in raw_value if str(item).strip()]
    else:
        text = str(raw_value).strip()
        if text:
            parts = [p.strip() for p in re.split(r"[,/\n]", text) if p.strip()]
            tokens = parts

    deduped = _dedup_preserve_order(tokens)
    joined = ", ".join(deduped)
    return joined, deduped


def _format_main_subjects(record: Any) -> list[Dict[str, str]]:
    """
    main_subject ë°°ì—´ì—ì„œ ê³¼ëª©ëª…ê³¼ ìš”ì•½ì„ ì¶”ì¶œí•´ LLM ì‘ë‹µì— ë°”ë¡œ í¬í•¨í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ê°€ê³µí•œë‹¤.
    """
    subjects: list[Dict[str, str]] = []
    raw_list = getattr(record, "main_subject", None)
    if not isinstance(raw_list, list):
        return subjects

    for item in raw_list:
        if not isinstance(item, dict):
            continue
        name = (item.get("SBJECT_NM") or item.get("subject_name") or "").strip()
        summary = _strip_html(item.get("SBJECT_SUMRY") or item.get("subject_description") or "").strip()
        if not name and not summary:
            continue
        entry: Dict[str, str] = {}
        if name:
            entry["SBJECT_NM"] = name
        if summary:
            entry["SBJECT_SUMRY"] = summary
        subjects.append(entry)

    return subjects


def _resolve_major_for_career(query: str) -> Any | None:
    """Helper to find the most relevant major record for career info."""
    if not query:
        return None

    # Use _find_majors to get the best match
    matches = _find_majors(query, limit=1)
    return matches[0] if matches else None


@tool
def list_departments(query: str, top_k: int = 10) -> str:
    """
    Pinecone majors vector DBë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ê³¼ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    - query = "ì „ì²´" â†’ ì „ì²´ ì „ê³µ ëª©ë¡ì„ ë°˜í™˜ (ìƒìœ„ top_kê¹Œì§€ë§Œ í‘œì‹œ)
    - query = "ì»´í“¨í„° / ì†Œí”„íŠ¸ì›¨ì–´ / ì¸ê³µì§€ëŠ¥" â†’ í•´ë‹¹ í‚¤ì›Œë“œì™€ ìœ ì‚¬í•œ ì „ê³µì„ ê²€ìƒ‰
    - query = "ì»´ê³µ" ë“± ë³„ì¹­ â†’ major_detail.jsonì—ì„œ ì¶”ì¶œí•œ ë³„ì¹­ ë§¤í•‘/ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ì •ê·œí™”
    - ë°˜í™˜ í¬ë§·ì—ëŠ” í•™ê³¼ëª…ê³¼ ê°œì„¤ ëŒ€í•™ ì˜ˆì‹œê°€ í•¨ê»˜ í¬í•¨ë©ë‹ˆë‹¤.
    """
    raw_query = (query or "").strip()
    _log_tool_start("list_departments", f"í•™ê³¼ ëª©ë¡ ì¡°íšŒ - query='{raw_query or 'ì „ì²´'}', top_k={top_k}")
    print(f"âœ… Using list_departments tool with query: '{raw_query}'")

    _ensure_major_records()

    # ì „ì²´ ëª©ë¡ ìš”ì²­
    if raw_query == "ì „ì²´" or not raw_query:
        dept_univ_map: dict[str, list[str]] = {}
        all_names = []
        for record in _get_major_records():
            if not record.major_name:
                continue
            all_names.append(record.major_name)
            pairs = _collect_university_pairs(record)
            if pairs:
                bucket = dept_univ_map.setdefault(record.major_name, [])
                for pair in pairs:
                    if pair not in bucket:
                        bucket.append(pair)
        all_names = sorted(set(all_names))
        limited = all_names[:top_k] if top_k else all_names
        print(f"âœ… Returning {len(limited)} majors out of {len(all_names)} total")
        result_text = _format_department_output(
            raw_query or "ì „ì²´",
            limited,
            total_available=len(all_names),
            dept_univ_map=dept_univ_map,
        )
        _log_tool_result("list_departments", f"ì´ {len(all_names)}ê°œ ì¤‘ {len(limited)}ê°œ ëª©ë¡ ë°˜í™˜")
        return result_text

    tokens, embed_text = _expand_category_query(raw_query)
    print(f"   â„¹ï¸ Expanded query tokens: {tokens}")
    print(f"   â„¹ï¸ Embedding text: '{embed_text}'")

    matches = _find_majors(raw_query, limit=max(top_k, 10))
    dept_univ_map: dict[str, list[str]] = {}

    for record in matches:
        pairs = _collect_university_pairs(record)
        if pairs:
            bucket = dept_univ_map.setdefault(record.major_name, [])
            for pair in pairs:
                if pair not in bucket:
                    bucket.append(pair)

    department_names = [record.major_name for record in matches if record.major_name]
    if not department_names:
        print("âš ï¸  WARNING: No majors found for the given query")
        _log_tool_result("list_departments", "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
        return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”."

    result = department_names[:top_k]
    print(f"âœ… Returning {len(result)} majors from major_detail vector DB")
    _log_tool_result("list_departments", f"{len(result)}ê°œ í•™ê³¼ ì •ë³´ ë°˜í™˜")
    return _format_department_output(raw_query, result, dept_univ_map=dept_univ_map)


@tool
def get_major_career_info(major_name: str) -> Dict[str, Any]:
    """
    íŠ¹ì • ì „ê³µ(major)ì— ëŒ€í•œ ì„¸ë¶„í™”ëœ ì§„ì¶œ ì§ì—… ëª©ë¡ê³¼ ì§„ì¶œ ë¶„ì•¼ ì„¤ëª…ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    ì¶”ê°€ë¡œ ì¶”ì²œ í™œë™, ê´€ë ¨ ìê²©ì¦, ì£¼ìš” ì „ê³µ ê³¼ëª© ì •ë³´ë„ í•¨ê»˜ ì œê³µí•©ë‹ˆë‹¤.

    Args:
        major_name: ì „ê³µëª… ë˜ëŠ” ë³„ì¹­ (ì˜ˆ: "ì»´í“¨í„°ê³µí•™ê³¼", "AIìœµí•©í•™ë¶€")

    Returns:
        {
            "major": "ì»´í“¨í„°ê³µí•™ê³¼",
            "jobs": ["3Dí”„ë¦°íŒ…ì „ë¬¸ê°€", ...],
            "job_summary": "3Dí”„ë¦°íŒ…ì „ë¬¸ê°€, ...",
            "enter_field": [{"category": "ê¸°ì—… ë° ì‚°ì—…ì²´", "description": "..."}, ...],
            "career_act": [{"act_name": "ê±´ì¶•ë°•ëŒíšŒ", "act_description": "..."}, ...],
            "qualifications": "ê±´ì¶•ê¸°ì‚¬, ...",
            "qualifications_list": ["ê±´ì¶•ê¸°ì‚¬", ...],
            "main_subject": [{"SBJECT_NM": "ê±´ì¶•êµ¬ì¡°ì‹œìŠ¤í…œ", "SBJECT_SUMRY": "..."}, ...],
            "source": "backend/data/major_detail.json"
        }
    """
    query = (major_name or "").strip()
    _log_tool_start("get_major_career_info", f"ì „ê³µ ì§„ë¡œ ì •ë³´ ì¡°íšŒ - major='{query}'")
    print(f"âœ… Using get_major_career_info tool for: '{query}'")

    if not query:
        result = {
            "error": "invalid_query",
            "message": "ì „ê³µëª…ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.",
            "suggestion": "ì˜ˆ: 'ì»´í“¨í„°ê³µí•™ê³¼', 'ì†Œí”„íŠ¸ì›¨ì–´ê³µí•™ê³¼'"
        }
        _log_tool_result("get_major_career_info", "ì „ê³µëª… ëˆ„ë½ - ì˜¤ë¥˜ ë°˜í™˜")
        return result

    record = _resolve_major_for_career(query)
    if record is None:
        print(f"âš ï¸  WARNING: No career data found for '{query}'")
        result = {
            "error": "no_results",
            "message": f"'{query}' ì „ê³µì˜ ì§„ì¶œ ì§ì—… ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "suggestion": "í•™ê³¼ëª…ì„ ì •í™•íˆ ì…ë ¥í•˜ê±°ë‚˜ list_departments íˆ´ë¡œ ì „ê³µëª…ì„ ë¨¼ì € í™•ì¸í•˜ì„¸ìš”."
        }
        _log_tool_result("get_major_career_info", "ì „ê³µ ë°ì´í„° ë¯¸ë°œê²¬ - ì˜¤ë¥˜ ë°˜í™˜")
        return result

    job_text = (getattr(record, "job", "") or "").strip()
    job_list = _extract_job_list(job_text)
    enter_field = _format_enter_field(record)
    career_activities = _format_career_activities(record)
    qualifications_text, qualifications_list = _parse_qualifications(record)
    main_subjects = _format_main_subjects(record)

    response: Dict[str, Any] = {
        "major": record.major_name,
        "jobs": job_list,
        "job_summary": job_text,
        "enter_field": enter_field,
        "source": "backend/data/major_detail.json"
    }

    if career_activities:
        response["career_act"] = career_activities
    if qualifications_text:
        response["qualifications"] = qualifications_text
    if qualifications_list:
        response["qualifications_list"] = qualifications_list
    if main_subjects:
        response["main_subject"] = main_subjects

    if not job_list:
        response["warning"] = "ë°ì´í„°ì— ë“±ë¡ëœ ì§ì—… ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
    else:
        print(f"âœ… Retrieved {len(job_list)} jobs for '{record.major_name}'")

    if enter_field:
        print(f"   â„¹ï¸ Enter field categories: {[item.get('category') for item in enter_field]}")

    activity_info = f"í™œë™ {len(career_activities)}ê±´" if career_activities else "í™œë™ ì •ë³´ ì—†ìŒ"
    subject_info = f"ì£¼ìš” ê³¼ëª© {len(main_subjects)}ê±´" if main_subjects else "ì£¼ìš” ê³¼ëª© ì •ë³´ ì—†ìŒ"
    _log_tool_result(
        "get_major_career_info",
        f"{record.major_name} - ì§ì—… {len(job_list)}ê±´, {activity_info}, {subject_info} ë°˜í™˜",
    )
    return response


@tool
def get_universities_by_department(department_name: str) -> List[Dict[str, str]]:
    """
    íŠ¹ì • í•™ê³¼ê°€ ìˆëŠ” ëŒ€í•™ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.

    ** ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ **
    - í•™ìƒì´ íŠ¹ì • í•™ê³¼ë¥¼ ì„ íƒí•œ í›„, í•´ë‹¹ í•™ê³¼ê°€ ìˆëŠ” ëŒ€í•™ë“¤ì„ ë³´ì—¬ì¤„ ë•Œ ì‚¬ìš©
    - ì˜ˆ: "ì»´í“¨í„°ê³µí•™ê³¼"ë¥¼ ì„ íƒí•˜ë©´ â†’ ì„œìš¸ëŒ€, ì—°ì„¸ëŒ€, ê³ ë ¤ëŒ€ ë“± ëª©ë¡ ì œê³µ

    Args:
        department_name: í•™ê³¼ëª… (ì˜ˆ: "ì»´í“¨í„°ê³µí•™ê³¼", "ì†Œí”„íŠ¸ì›¨ì–´í•™ë¶€")

    Returns:
        ëŒ€í•™ ì •ë³´ ë¦¬ìŠ¤íŠ¸ [
            {"university": "ì„œìš¸ëŒ€í•™êµ", "college": "ê³µê³¼ëŒ€í•™", "department": "ì»´í“¨í„°ê³µí•™ê³¼"},
            {"university": "ì—°ì„¸ëŒ€í•™êµ", "college": "ê³µê³¼ëŒ€í•™", "department": "ì»´í“¨í„°ê³µí•™ê³¼"},
            ...
        ]
    """
    query = (department_name or "").strip()
    _log_tool_start("get_universities_by_department", f"í•™ê³¼ë³„ ëŒ€í•™ ì¡°íšŒ - department='{query}'")
    print(f"âœ… Using get_universities_by_department tool for: '{query}'")

    if not query:
        result = [{
            "error": "invalid_query",
            "message": "í•™ê³¼ëª…ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.",
            "suggestion": "ì˜ˆ: 'ì»´í“¨í„°ê³µí•™ê³¼', 'ì†Œí”„íŠ¸ì›¨ì–´í•™ë¶€'"
        }]
        _log_tool_result("get_universities_by_department", "í•™ê³¼ëª… ëˆ„ë½ - ì˜¤ë¥˜ ë°˜í™˜")
        return result

    _ensure_major_records()

    matches: list[Any] = []
    direct = _lookup_major_by_name(query)
    if direct:
        matches.append(direct)
    else:
        # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” í•™ê³¼ê°€ ì—†ìœ¼ë©´ ìœ ì‚¬ í•™ê³¼ ê²€ìƒ‰
        matches = _find_majors(query, limit=5)

    aggregated: list[Dict[str, str]] = []
    for record in matches:
        entries = _extract_university_entries(record)
        if entries:
            aggregated.extend(entries)
        if len(aggregated) >= 50:
            break

    if not aggregated:
        print(f"âš ï¸  WARNING: No universities found offering '{query}' in major_detail.json")
        result = [{
            "error": "no_results",
            "message": f"'{query}' í•™ê³¼ë¥¼ ê°œì„¤í•œ ëŒ€í•™ ì •ë³´ë¥¼ major_detail ë°ì´í„°ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "suggestion": "í•™ê³¼ëª…ì„ ì •í™•íˆ ì…ë ¥í•˜ê±°ë‚˜ list_departments íˆ´ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ì „ê³µëª…ì„ ë¨¼ì € í™•ì¸í•˜ì„¸ìš”."
        }]
        _log_tool_result("get_universities_by_department", "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ - ì˜¤ë¥˜ ë°˜í™˜")
        return result

    print(f"âœ… Found {len(aggregated)} university rows for '{query}'")
    for entry in aggregated[:5]:
        print(
            f"   - {entry.get('university')} / {entry.get('college')} / "
            f"{entry.get('department')}"
        )
    _log_tool_result("get_universities_by_department", f"ì´ {len(aggregated)}ê±´ ëŒ€í•™ ì •ë³´ ë°˜í™˜")
    return aggregated


@tool
def get_search_help() -> str:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì—ˆì„ ë•Œ ì‚¬ìš©í•˜ëŠ” íˆ´ì…ë‹ˆë‹¤.
    ê²€ìƒ‰ ê°€ëŠ¥í•œ ë°©ë²•ë“¤(ê° íˆ´ì„ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” ë°©ë²•ë“¤)ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.

    ** ì–¸ì œ ì‚¬ìš©í•˜ë‚˜ìš”? **
    1. ë‹¤ë¥¸ íˆ´(list_departments, get_universities_by_department)ì˜ ê²°ê³¼ê°€ ë¹„ì–´ìˆì„ ë•Œ
    2. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ë„ˆë¬´ ëª¨í˜¸í•˜ê±°ë‚˜ ë°ì´í„°ë² ì´ìŠ¤ì— ì—†ëŠ” ì •ë³´ë¥¼ ìš”ì²­í•  ë•Œ
    3. ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì–´ì„œ ì‚¬ìš©ìì—ê²Œ ë‹¤ë¥¸ ê²€ìƒ‰ ë°©ë²•ì„ ì•ˆë‚´í•´ì•¼ í•  ë•Œ

    Returns:
        ê²€ìƒ‰ ê°€ëŠ¥í•œ ë°©ë²•ë“¤ì„ ì„¤ëª…í•˜ëŠ” ê°€ì´ë“œ ë©”ì‹œì§€
    """
    _log_tool_start("get_search_help", "ê²€ìƒ‰ ê°€ì´ë“œ ì•ˆë‚´")
    print("â„¹ï¸  Using get_search_help tool - providing usage guide to user")
    message = _get_tool_usage_guide()
    _log_tool_result("get_search_help", "ì‚¬ìš©ì ê°€ì´ë“œ ë©”ì‹œì§€ ë°˜í™˜")
    return message
