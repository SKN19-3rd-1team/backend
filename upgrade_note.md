지금 쓰는 Qwen2.5-7B 급 모델을 그대로 두고도, **LangGraph 구조 + 툴 + (가벼운) 파인튜닝**만 잘 써도 체감 성능 꽤 올릴 수 있어요.
특히 "없는 과목 막 만들어내는 문제"는 **그래프 설계 + 출력 제약**으로 많이 줄일 수 있고요.

아래 3가지 정도를 추천할게요.

---

## 1. 멀티-모델 그래프: "작은 모델 + 검증/보강 모델" 조합

LangGraph는 노드마다 **다른 모델**을 쓸 수 있어서,
한 번에 한 모델에 올인하지 않고 **역할을 나눠서** 성능을 끌어올릴 수 있어요.

### 구조 예시

1. **Router / 파서용 노드 (작은 한국어 특화 모델)**

   * 학생 입력 → 대학/학과/학년/학기/관심사를 JSON으로 뽑는 전용 노드
2. **RAG + 답변 초안 노드 (Qwen2.5-7B-Instruct 등 메인 모델)**

   * 필터 + RAG 컨텍스트 기반으로 답변 초안 생성
3. **검증 노드 (동일 모델 or 조금 더 큰/신뢰도 높은 모델)**

   * “답변에 등장하는 과목들이 전부 벡터DB 안에 존재하는지” 확인
   * 존재하지 않는 과목명 → 수정 요청 or 제거

### 왜 효과가 있나

* 작은 모델 하나에 모든 걸 맡기면 **파싱/추론/설명/검증을 다 해야 해서** 환각이 늘어납니다.
* LangGraph로 역할을 분리하면,

  * “파싱에 강한 모델”
  * “대화에 강한 모델”
  * “검증에만 쓰는 모델”
    을 조합해서 **전체 시스템 성능**을 올릴 수 있어요.

---

## 2. Corrective RAG(cRAG) / Self-Check 루프 넣기

지금은 한 번 답변 만들고 끝인데, LangGraph로는 **“초안 → 검토 → 수정” 루프**를 쉽게 만들 수 있습니다.
최근에 LangChain/LangGraph로 Corrective RAG(cRAG) 구현하는 예제가 꽤 나왔어요.

### 그래프 패턴

1. `draft_answer_node`

   * 지금 answer_node처럼 RAG 기반으로 답변 생성
2. `critique_node`

   * 입력: 초안 답변 + retrieved_docs
   * 역할:

     * 과목명이 `retrieved_docs.metadata["name"]` 안에 있는지 체크
     * 없는 과목 → “이 과목은 커리큘럼에 없음”이라고 플래그
3. `decide_node`

   * 플래그가 있으면 → `draft_answer_node`로 다시 보내거나
   * 사용자에게 “이 과목은 실제 커리큘럼에 없는데, 비슷한 대체 과목을 추천할까요?” 같은 질문

### 장점

* 작은 모델이 실수(환각)를 하더라도,
  **두 번째 노드에서 “과목명 검증”만 따로 수행**하니까
  “커리큘럼에 없는 과목 대잔치”가 크게 줄어듭니다.

---

## 3. Qwen2.5 계열 경량 파인튜닝 + LangGraph에서 "핵심 노드에만 적용"

“모델을 갈아치우는” 게 아니라,
**지금 Qwen2.5-7B 급 모델을 “내 도메인 전용 과목 추천/설명 작업”에 살짝 맞게 파인튜닝**하면,
같은 파라미터 수에서도 꽤 성능 차이가 납니다.

요즘은 LLaMA-Factory 같은 툴로 Qwen2.5 모델도 LoRA/QLoRA로 쉽게 튜닝할 수 있어요.

### 어떻게 쓰면 좋은지

1. **데이터 준비**

   * (질문, retrieved_docs, “정답 과목 리스트 + 설명”) 형태로
     몇 천~몇 만 건 정도의 SFT 데이터
   * 이미 만든 JSON + LangGraph 로그를 이용해서 **반자동으로 생성** 가능

2. **파인튜닝**

   * LLaMA-Factory 등에서:

     * base: `Qwen/Qwen2.5-7B-Instruct`
     * task: “전공/과목 추천 + 설명”
     * output 포맷: “컨텍스트 안 과목만 사용, 번호/ID로 선택” 식으로 고정

3. **LangGraph 통합**

   * 기존 `answer_node` 만 모델을 `qwen2.5-7b-instruct-mentoring-finetuned` 로 교체
   * 나머지 노드(entity 추출, retriever 등)는 기존 모델/규칙 유지

### 장점

* 전체 시스템을 다 바꾸지 않고,
  **“가장 중요한 핵심 노드”에만 튜닝된 모델을 꽂아서 성능을 끌어올리는 패턴**이라 리스크가 적어요.
* 작은 7B 모델도, 도메인 파인튜닝 + RAG + 검증 루프까지 합치면
  꽤 “대형 모델 느낌”의 안정성을 낼 수 있습니다.

---

## 정리

* **LangGraph 관점**에서 성능을 올리는 핵심은:

  1. **툴(벡터DB, DB 조회, 검증 로직)을 적극적으로 끼워 넣고**
  2. **역할을 나눈 여러 노드/모델을 조합**하고
  3. 필요하면 **도메인 전용 파인튜닝 모델을 “핵심 노드에만” 꽂는 것**

이 세 가지예요.

원하면,
지금 쓰고 있는 그래프에 맞춰서

* 위 3가지 중 하나를
* 실제 LangGraph 코드 구조로 어떻게 바꿀지

를 단계별로 같이 뜯어서 설계도(노드 다이어그램 + pseudo-code)까지 그려줄게.
