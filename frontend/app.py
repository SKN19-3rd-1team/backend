"""
ì „ê³µ íƒìƒ‰ ë©˜í†  ì±—ë´‡ - Streamlit Frontend

ëŒ€í•™ ê³¼ëª© ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìƒë“¤ì—ê²Œ ë§ì¶¤ ê³¼ëª© ì¶”ì²œê³¼ ì§„ë¡œ ìƒë‹´ì„ ì œê³µí•˜ëŠ” ì±—ë´‡ UIì…ë‹ˆë‹¤.
ë°±ì—”ë“œì˜ LangGraph ê¸°ë°˜ RAG ì‹œìŠ¤í…œê³¼ ì—°ê²°ë˜ì–´ ì‹¤ì‹œê°„ìœ¼ë¡œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ë‹µë³€í•©ë‹ˆë‹¤.

** ì£¼ìš” ê¸°ëŠ¥ **
1. ì±„íŒ… ê¸°ë°˜ ì¸í„°í˜ì´ìŠ¤ (Streamlit Chat)
2. ê´€ì‹¬ì‚¬ ì…ë ¥ ê¸°ëŠ¥ (ì‚¬ì´ë“œë°”)
3. ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ (Session State)
4. ì‹¤ì‹œê°„ ì‘ë‹µ (run_mentor í•¨ìˆ˜ í˜¸ì¶œ)

** ì‹¤í–‰ ë°©ë²• **
```bash
streamlit run frontend/app.py
```
"""
# frontend/app.py
import streamlit as st
from pathlib import Path
import sys

# ==================== ê²½ë¡œ ì„¤ì • ====================
# backend ëª¨ë“ˆì„ importí•˜ê¸° ìœ„í•´ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
ROOT_DIR = Path(__file__).resolve().parents[1]  # frontendì˜ ë¶€ëª¨ = í”„ë¡œì íŠ¸ ë£¨íŠ¸
sys.path.append(str(ROOT_DIR))

# ==================== Backend ëª¨ë“ˆ Import ====================
from backend.main import run_mentor, run_major_recommendation  # ë°±ì—”ë“œ ë©”ì¸ í•¨ìˆ˜
from backend.config import get_settings  # ì„¤ì • ë¡œë“œ

# ==================== ì„¤ì • ë¡œë“œ ë° ì½˜ì†” ì¶œë ¥ ====================
settings = get_settings()
print(
    f"[Mentor Console] Using provider '{settings.llm_provider}' "
    f"with model '{settings.model_name}'"
)

# ==================== ì¹´í…Œê³ ë¦¬ ë° ì˜¨ë³´ë”© ì •ì˜ ====================

ONBOARDING_QUESTIONS = [
    {
        "key": "subjects",
        "label": "ì„ í˜¸ ê³ êµ ê³¼ëª©",
        "prompt": "ì•ˆë…•í•˜ì„¸ìš”! ê°€ì¥ ì¢‹ì•„í•˜ê±°ë‚˜ ìì‹  ìˆëŠ” ê³ ë“±í•™êµ ê³¼ëª©ì€ ë¬´ì—‡ì¸ê°€ìš”? ì¢‹ì•„í•˜ëŠ” ì´ìœ ë„ í•¨ê»˜ ì•Œë ¤ì£¼ì„¸ìš”.",
        "placeholder": "ì˜ˆ: ìˆ˜í•™ê³¼ ë¬¼ë¦¬ë¥¼ íŠ¹íˆ ì¢‹ì•„í•˜ê³  ì‹¤í—˜ ìˆ˜ì—…ì„ ì¦ê¹ë‹ˆë‹¤."
    },
    {
        "key": "interests",
        "label": "í¥ë¯¸ ë° ì·¨ë¯¸",
        "prompt": "í•™êµ ë°–ì—ì„œëŠ” ì–´ë–¤ ì£¼ì œë‚˜ ì·¨ë¯¸ì— ê°€ì¥ í¥ë¯¸ë¥¼ ëŠë¼ë‚˜ìš”?",
        "placeholder": "ì˜ˆ: ë¡œë´‡ ë™ì•„ë¦¬ í™œë™, ë””ì§€í„¸ ë“œë¡œì‰, ìŒì•… ê°ìƒ ë“±"
    },
    {
        "key": "desired_salary",
        "label": "í¬ë§ ì—°ë´‰",
        "prompt": "ì¡¸ì—… í›„ ì–´ëŠ ì •ë„ì˜ ì—°ë´‰ì„ í¬ë§í•˜ë‚˜ìš”? ëŒ€ëµì ì¸ ìˆ˜ì¤€ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
        "placeholder": "ì˜ˆ: ì—° 4ì²œë§Œ ì› ì´ìƒì´ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤."
    },
    {
        "key": "preferred_majors",
        "label": "í¬ë§ í•™ê³¼",
        "prompt": "ê°€ì¥ ì§„í•™í•˜ê³  ì‹¶ì€ í•™ê³¼ë‚˜ ì „ê³µì€ ë¬´ì—‡ì¸ê°€ìš”? ë³µìˆ˜ë¡œ ë‹µí•´ë„ ê´œì°®ì•„ìš”.",
        "placeholder": "ì˜ˆ: ì»´í“¨í„°ê³µí•™ê³¼, ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤í•™ê³¼"
    },
]

# ==================== Streamlit í˜ì´ì§€ ì„¤ì • ====================
st.set_page_config(
    page_title="ì „ê³µ íƒìƒ‰ ë©˜í† ",
    page_icon="ğŸ“",
    layout="wide"  # ë„“ì€ ë ˆì´ì•„ì›ƒ
)

# ==================== Session State ì´ˆê¸°í™” ====================
# Streamlit Session State: í˜ì´ì§€ ë¦¬ë¡œë“œ ì‹œì—ë„ ìœ ì§€ë˜ëŠ” ìƒíƒœ ì €ì¥ì†Œ

# ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™” (ì‚¬ìš©ìì™€ ì±—ë´‡ì˜ ëŒ€í™” ë‚´ìš©)
if "messages" not in st.session_state:
    st.session_state.messages = []

# ê´€ì‹¬ì‚¬ ì´ˆê¸°í™” (ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê´€ì‹¬ ë¶„ì•¼/ì§„ë¡œ ë°©í–¥)
if "interests" not in st.session_state:
    st.session_state.interests = ""



if "button_prompt" not in st.session_state:
    st.session_state.button_prompt = None
if 'format_pending' not in st.session_state:
    st.session_state.format_pending = False

if "onboarding_step" not in st.session_state:
    st.session_state.onboarding_step = 0
if "onboarding_answers" not in st.session_state:
    st.session_state.onboarding_answers = {q["key"]: "" for q in ONBOARDING_QUESTIONS}
if "onboarding_complete" not in st.session_state:
    st.session_state.onboarding_complete = False
if "major_recommendations" not in st.session_state:
    st.session_state.major_recommendations = None
if "major_profile_text" not in st.session_state:
    st.session_state.major_profile_text = ""
if "major_scores" not in st.session_state:
    st.session_state.major_scores = {}
if "major_hits" not in st.session_state:
    st.session_state.major_hits = []
if "major_recommendation_error" not in st.session_state:
    st.session_state.major_recommendation_error = None
if "new_major_summary" not in st.session_state:
    st.session_state.new_major_summary = False
if "force_recalc_major" not in st.session_state:
    st.session_state.force_recalc_major = False




def ensure_onboarding_flow():
    """ì´ˆê¸° 4ë‹¨ê³„ ì„ í˜¸ë„ ì¡°ì‚¬ê°€ ëë‚  ë•Œê¹Œì§€ ì±„íŒ… UIë¥¼ ì ì‹œ ìˆ¨ê¸´ë‹¤."""
    if st.session_state.onboarding_complete:
        return

    st.subheader("ğŸ§‘â€ğŸ« ë¨¼ì € ê°„ë‹¨í•œ ì„ í˜¸ë„ ì¡°ì‚¬ë¥¼ ì§„í–‰í•´ë³¼ê²Œìš”")
    st.info("ì•„ë˜ 4ê°€ì§€ ì§ˆë¬¸ì— ìˆœì„œëŒ€ë¡œ ë‹µí•´ì£¼ì‹œë©´ ë§ì¶¤í˜• ì „ê³µ ì¶”ì²œì„ ì¤€ë¹„í•  ìˆ˜ ìˆì–´ìš”.")
    step = st.session_state.onboarding_step

    # ì´ì „ ì§ˆë¬¸/ë‹µë³€ì„ ê°„ë‹¨í•œ ëŒ€í™” í˜•íƒœë¡œ ë³´ì—¬ì£¼ê¸°
    for idx in range(step):
        q = ONBOARDING_QUESTIONS[idx]
        answer = st.session_state.onboarding_answers.get(q["key"], "")
        with st.chat_message("assistant"):
            st.markdown(q["prompt"])
        if answer:
            with st.chat_message("user"):
                st.markdown(answer)

    current = ONBOARDING_QUESTIONS[step]
    with st.chat_message("assistant"):
        st.markdown(current["prompt"])

    form_key = f"onboarding_form_{step}"
    input_key = f"onboarding_input_{step}"
    with st.form(form_key, clear_on_submit=False):
        response = st.text_input(
            "ë‹µë³€ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”",
            value=st.session_state.onboarding_answers.get(current["key"], ""),
            key=input_key,
            placeholder=current.get("placeholder", "")
        )
        submitted = st.form_submit_button("ë‹¤ìŒ ì§ˆë¬¸")

    if submitted:
        if not response.strip():
            st.warning("ë‹µë³€ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        else:
            st.session_state.onboarding_answers[current["key"]] = response.strip()
            st.session_state.onboarding_step += 1
            if st.session_state.onboarding_step >= len(ONBOARDING_QUESTIONS):
                st.session_state.onboarding_complete = True
            st.rerun()

    st.stop()


def ensure_major_recommendations(force: bool = False):
    """ì˜¨ë³´ë”©ì´ ì™„ë£Œë˜ë©´ Pinecone ê¸°ë°˜ ì „ê³µ ì¶”ì²œì„ í˜¸ì¶œí•œë‹¤."""
    if not st.session_state.onboarding_complete:
        return

    needs_fetch = force or st.session_state.major_recommendations is None
    if not needs_fetch:
        return

    st.session_state.major_recommendation_error = None
    with st.spinner("ì˜¨ë³´ë”© ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ê³µì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        try:
            result = run_major_recommendation(
                onboarding_answers=st.session_state.onboarding_answers,
                question=None
            )
        except Exception as exc:
            st.session_state.major_recommendations = []
            st.session_state.major_profile_text = ""
            st.session_state.major_scores = {}
            st.session_state.major_hits = []
            st.session_state.major_recommendation_error = str(exc)
            st.session_state.new_major_summary = False
            return

    st.session_state.major_recommendations = result.get("recommended_majors", [])
    st.session_state.major_profile_text = result.get("user_profile_text", "")
    st.session_state.major_scores = result.get("major_scores", {})
    st.session_state.major_hits = result.get("major_search_hits", [])
    st.session_state.new_major_summary = True


def render_major_recommendations_section():
    """ì¶”ì²œëœ ì „ê³µì„ ì¹´ë“œ í˜•íƒœë¡œ ì •ë¦¬."""
    st.subheader("ğŸ§­ ë§ì¶¤ ì „ê³µ ì¶”ì²œ ê²°ê³¼")

    if st.session_state.major_recommendation_error:
        st.error(
            "ì „ê³µ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.\n\n"
            f"ìƒì„¸ ë©”ì‹œì§€: {st.session_state.major_recommendation_error}"
        )
        if st.button("ğŸ” ë‹¤ì‹œ ì‹œë„", key="retry_major_rec"):
            st.session_state.major_recommendations = None
            st.session_state.major_recommendation_error = None
            st.session_state.force_recalc_major = True
            st.rerun()
        return

    recs = st.session_state.major_recommendations
    if recs is None:
        st.info("ì¶”ì²œ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
        return

    if not recs:
        st.warning("ì¡°ê±´ì— ë§ëŠ” ì „ê³µì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹µë³€ì„ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì ì–´ë³´ì„¸ìš”.")
    else:
        if st.session_state.major_profile_text:
            st.caption("í•™ìƒ í”„ë¡œí•„ ìš”ì•½")
            st.code(st.session_state.major_profile_text.strip())

        for idx, major in enumerate(recs[:5], start=1):
            score = major.get("score", 0.0)
            cluster = major.get("cluster") or "ê³„ì—´ ì •ë³´ ì—†ìŒ"
            salary = major.get("salary")
            tags = major.get("relate_subject_tags", [])[:5]
            doc_types = ", ".join(
                f"{doc_type}({doc_score:.2f})"
                for doc_type, doc_score in major.get("top_doc_types", [])
            )
            with st.container():
                st.markdown(f"**{idx}. {major['major_name']}** Â· ì ìˆ˜ {score:.2f}")
                st.write(f"- ê³„ì—´: {cluster}")
                if salary is not None:
                    salary_text = f"{salary}ë§Œì›" if isinstance(salary, (int, float)) else f"{salary}"
                    st.write(f"- í‰ê·  ì´ˆë´‰ ì§€í‘œ: {salary_text}")
                if doc_types:
                    st.write(f"- ì£¼ìš” ê·¼ê±°: {doc_types}")
                if tags:
                    st.write(f"- ì—°ê´€ ê³¼ëª© íƒœê·¸: {', '.join(tags)}")
                
                # summary í•„ë“œ í‘œì‹œ
                summary_text = major.get("summary", "")
                if summary_text:
                    st.caption("ìƒì„¸ ì„¤ëª…")
                    st.markdown(summary_text)

    rerun_col1, rerun_col2 = st.columns([1, 4])
    with rerun_col1:
        if st.button("ğŸ” ì „ê³µ ì¶”ì²œ ë‹¤ì‹œ ë¶„ì„", key="rerun_major_button"):
            st.session_state.major_recommendations = None
            st.session_state.major_recommendation_error = None
            st.session_state.force_recalc_major = True
            st.rerun()
    with rerun_col2:
        st.caption("ë‹µë³€ì„ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ìˆ˜ì •í•˜ë©´ ì¶”ì²œ ì •í™•ë„ê°€ ì˜¬ë¼ê°‘ë‹ˆë‹¤.")


def sync_major_summary_message():
    """ìƒˆ ì¶”ì²œ ê²°ê³¼ê°€ ìˆì„ ë•Œ ì±—ë´‡ ëŒ€í™”ì—ë„ ìš”ì•½ì„ ë‚¨ê¸´ë‹¤."""
    if not st.session_state.get("new_major_summary"):
        return

    recs = st.session_state.major_recommendations or []
    if not recs:
        st.session_state.new_major_summary = False
        return

    lines = []
    for idx, major in enumerate(recs[:5], start=1):
        score = major.get("score", 0.0)
        lines.append(f"{idx}. {major['major_name']} (ì ìˆ˜ {score:.2f})")
    summary_text = (
        "ì˜¨ë³´ë”© ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ì¶”ì²œ ì „ê³µ TOP 5ë¥¼ ì •ë¦¬í–ˆì–´ìš”:\n"
        + "\n".join(lines)
        + "\n\ní•„ìš”í•˜ë©´ ìœ„ ì „ê³µ ì¤‘ ê¶ê¸ˆí•œ í•™ê³¼ë¥¼ ì§€ì •í•´ì„œ ë” ë¬¼ì–´ë´ë„ ì¢‹ì•„ìš”!"
    )
    st.session_state.messages.append({"role": "assistant", "content": summary_text})
    st.session_state.new_major_summary = False


st.title("ğŸ“ ì „ê³µ íƒìƒ‰ ë©˜í†  ì±—ë´‡")
st.write("ì´ê³µê³„ì—´ ê³¼ëª©ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ, ë‚˜ì—ê²Œ ë§ëŠ” ê³¼ëª©ê³¼ ì§„ë¡œë¥¼ í•¨ê»˜ ê³ ë¯¼í•´ë³´ëŠ” ë©˜í†  ì±—ë´‡ì…ë‹ˆë‹¤.")

# ì˜¨ë³´ë”© ì„¤ë¬¸ì´ ëë‚˜ì§€ ì•Šì•˜ë‹¤ë©´ ì¦‰ì‹œ ì§„í–‰
ensure_onboarding_flow()

# ì˜¨ë³´ë”© ì™„ë£Œ í›„ ì „ê³µ ì¶”ì²œ ì‹¤í–‰ ë° ìš”ì•½ í‘œì‹œ
force_flag = st.session_state.force_recalc_major
if force_flag:
    st.session_state.force_recalc_major = False
ensure_major_recommendations(force=force_flag)
render_major_recommendations_section()
st.divider()

# ì»¤ë¦¬í˜ëŸ¼ í‚¤ì›Œë“œ ê°ì§€ í•¨ìˆ˜
def is_curriculum_query(text: str) -> bool:
    keywords = ["ì»¤ë¦¬í˜ëŸ¼", "í•™ê¸°ë³„", "ì „ì²´ ì»¤ë¦¬í˜ëŸ¼", "í•™ë…„ë³„", "ìˆ˜ì—… ìˆœì„œ", "ì»¤ë¦¬í˜ëŸ¼ì„"]
    return any(keyword in text for keyword in keywords)

# ë²„íŠ¼ ë Œë”ë§ í•¨ìˆ˜
def render_format_options_inline(original_question: str):
    option_labels = ["ìš”ì•½í˜•", "ìƒì„¸í˜•", "í‘œ í˜•íƒœ"]
    st.write("ì›í•˜ì‹œëŠ” ì¶œë ¥ í˜•ì‹ì„ ì„ íƒí•´ ì£¼ì„¸ìš”")
    cols = st.columns(len(option_labels))
    for i, label in enumerate(option_labels):
        with cols[i]:
            st.button(label, on_click=handle_button_click, args=[label], key=f"inline_opt_{label}")

# ë²„íŠ¼ í´ë¦­ ì²˜ë¦¬ í•¨ìˆ˜
def handle_button_click(selection: str):
    original_question = ""
    for msg in reversed(st.session_state.messages):
            if msg["role"] == "user":
                original_question = msg["content"]
                break

    display_prompt = f"{original_question}ì„ {selection}ìœ¼ë¡œ ë³´ì—¬ì¤˜"
    st.session_state.button_prompt = display_prompt


with st.sidebar:
    st.header("ë‚˜ì— ëŒ€í•œ ì •ë³´")
    st.info("ì˜¨ë³´ë”© ì§ˆë¬¸ì— ë‹µë³€í•˜ì‹œë©´ ë§ì¶¤í˜• ì „ê³µ ì¶”ì²œì„ ë°›ìœ¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")



# ==================== ì±„íŒ… ê¸°ë¡ í‘œì‹œ ====================
# Session Stateì— ì €ì¥ëœ ì´ì „ ëŒ€í™” ë‚´ìš©ì„ í™”ë©´ì— í‘œì‹œ
sync_major_summary_message()
chat_container = st.container()
with chat_container:
    for message in st.session_state.messages:
        # "user" ë˜ëŠ” "assistant" ì—­í• ì— ë§ëŠ” ì±„íŒ… ë©”ì‹œì§€ UI ìƒì„±
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

prompt = None

new_input = st.chat_input("ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”!")

# ë²„íŠ¼ í´ë¦­ìœ¼ë¡œ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬
if st.session_state.button_prompt:
    prompt = st.session_state.button_prompt
    st.session_state.button_prompt = None
elif new_input:
    # ì¼ë°˜ í…ìŠ¤íŠ¸ ì…ë ¥ ì²˜ë¦¬
    prompt = new_input

# Chat input
if prompt:
    if is_curriculum_query(prompt) and not st.session_state.button_prompt and not st.session_state.format_pending:
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        render_format_options_inline(prompt)
        st.session_state.format_pending = True
        st.stop()

    # If we are resuming after the user chose a format (button_prompt was set), avoid duplicating the user message
    if st.session_state.format_pending and st.session_state.button_prompt is None:
        pass

    # Add user message to chat history if not already added by format flow
    if not st.session_state.format_pending:
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
            
        display_content = prompt
    else:
        # We're resuming after a format selection; show the original user message
        display_content = None
        for msg in reversed(st.session_state.messages):
            if msg.get("role") == "user":
                display_content = msg.get("content")
                break

        if display_content is None:
            display_content = prompt

    # 3. ë°±ì—”ë“œ í˜¸ì¶œí•˜ì—¬ ë‹µë³€ ìƒì„±
    with st.chat_message("assistant"):
        # ë¡œë”© ìŠ¤í”¼ë„ˆ í‘œì‹œ
        with st.spinner("ë©˜í† ê°€ ê³¼ëª© ì •ë³´ë¥¼ ê²€í†  ì¤‘ì…ë‹ˆë‹¤..."):
            run_question = prompt
            if st.session_state.get('internal_marker'):
                run_question = f"{prompt} {st.session_state.get('internal_marker')}"

            # ì˜¨ë³´ë”© í”„ë¡œí•„ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ì „ë‹¬
            profile_context = (
                st.session_state.interests
                or st.session_state.major_profile_text
            )

            raw_response: str | dict = run_mentor(
                question=run_question,
                interests=profile_context or None,
                chat_history=st.session_state.messages
            )

            if st.session_state.get('internal_marker'):
                del st.session_state['internal_marker']
        
        # ì¼ë°˜ í…ìŠ¤íŠ¸ ì‘ë‹µ ì²˜ë¦¬
        response_content = raw_response
        st.markdown(response_content) # ì¼ë°˜ í…ìŠ¤íŠ¸ëŠ” ì¦‰ì‹œ ì¶œë ¥

    # Add assistant response to chat history
    st.session_state.messages.append({"role": "assistant", "content": response_content})

    if st.session_state.format_pending:
        st.session_state.format_pending = False
        st.session_state.button_prompt = None
        if 'format_origin' in st.session_state:
            del st.session_state['format_origin']
